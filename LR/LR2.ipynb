{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7781455,"sourceType":"datasetVersion","datasetId":4553641}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Подключение библиотек\nimport pandas as pd\nimport numpy as np\n\npath_to_file = '/kaggle/input/student-study-performance/study_performance.csv'\n\n# Попытка загрузить датасет\ntry:\n    data = pd.read_csv(path_to_file)\n    print(\"Датасет успешно загружен.\")\n    print(data.head())  # Показать первые пять строк данных\nexcept FileNotFoundError:\n    print(f\"Файл не найден: убедитесь, что путь к файлу корректен ({path_to_file})\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T20:03:33.617110Z","iopub.execute_input":"2024-04-07T20:03:33.617560Z","iopub.status.idle":"2024-04-07T20:03:33.646099Z","shell.execute_reply.started":"2024-04-07T20:03:33.617525Z","shell.execute_reply":"2024-04-07T20:03:33.645257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Здесь представлена таблица датасета, который, относится к оценке учебной производительности студентов. Представленные данные:\n-gender: Пол ученика — женский (female) или мужской (male).\n-race_ethnicity: Этническая принадлежность учеников, классифицированная по группам от A до C (возможно, существуют и другие группы в полном датасете).\n-parental_level_of_education: Уровень образования родителей, который варьируется от \"some college\" (некоторое количество колледжного образования), до \"bachelor's degree\" (степень бакалавра) и \"master's degree\" (степень магистра).\n-lunch: Тип питания, которое предоставляется ученику в школе — \"standard\" (стандартное) или \"free/reduced\" (бесплатное/со скидкой).\n-test_preparation_course: Указывает на то, закончил ли ученик курс подготовки к тестам (\"completed\") или нет (\"none\").\n-math_score: Оценка ученика по математике.\n-reading_score: Оценка ученика по чтению.\n-writing_score: Оценка ученика по письму.\nЭти данные могут использоваться для анализа связи между социально-экономическими факторами (такими как этническая принадлежность, образование родителей и тип питания) и учебной производительностью студентов, а также влиянием курса подготовки на оценки.","metadata":{}},{"cell_type":"markdown","source":"**Проверка на наличие пропусков**","metadata":{}},{"cell_type":"code","source":"print(data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:06:43.829111Z","iopub.execute_input":"2024-04-07T20:06:43.829813Z","iopub.status.idle":"2024-04-07T20:06:43.837801Z","shell.execute_reply.started":"2024-04-07T20:06:43.829776Z","shell.execute_reply":"2024-04-07T20:06:43.836457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В каждом из столбцов датасета отсутствуют пропуски, поскольку количество пропущенных значений для каждого признака равно 0. Т.к. для ЛР2 мы работаем с пропусками ,следовательно создадим код, который создаст пропуски в датасете.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Загрузка данных, предположим, что это CSV файл с результатами экзаменов студентов\n# Убедитесь, что путь к файлу корректен и файл содержит необходимые колонки\ndata = pd.read_csv('/kaggle/input/student-study-performance/study_performance.csv')\n\n# Устанавливаем разное количество пропусков для разных колонок\nfrac_dict = {\n    'math_score': 0.1,  # 10% пропусков\n    'reading_score': 0.2,  # 20% пропусков\n    'writing_score': 0.15,  # 15% пропусков\n    'gender': 0.05,  # 5% пропусков\n    'race_ethnicity': 0.1,  # 10% пропусков\n    'parental_level_of_education': 0.1,  # 10% пропусков\n    'lunch': 0.2,  # 20% пропусков\n    'test_preparation_course': 0.15  # 15% пропусков\n}\n\n# Создаем пропуски в данных\nfor col, frac in frac_dict.items():\n    data.loc[data.sample(frac=frac, random_state=1).index, col] = np.nan\n\n# Проверяем, какие пропуски появились\nmissing_data = data.isnull().sum()\nprint(missing_data)\n\n# Строим диаграмму\nplt.figure(figsize=(10, 5))\nmissing_data.plot(kind='bar', color='skyblue')\nplt.title('Пропуски в данных')\nplt.xlabel('Колонки')\nplt.ylabel('Количество пропусков')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:19:43.265944Z","iopub.execute_input":"2024-04-08T07:19:43.266651Z","iopub.status.idle":"2024-04-08T07:19:43.739016Z","shell.execute_reply.started":"2024-04-08T07:19:43.266616Z","shell.execute_reply":"2024-04-08T07:19:43.737738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Обработка пропусков**","metadata":{}},{"cell_type":"markdown","source":"Для числовых признаков (например, math_score, reading_score, writing_score), обычно пропуски заполняют средним или медианным значением столбца:","metadata":{}},{"cell_type":"code","source":"for col in ['math_score', 'reading_score', 'writing_score']:\n    mean_before = data[col].mean()  # Среднее до замены пропусков\n    data[col] = data[col].fillna(mean_before)\n    mean_after = data[col].mean()  # Среднее после замены пропусков\n\n    # Визуализация результатов\n    plt.figure(figsize=(12, 6))\n    \n    # Подготовка данных для гистограммы\n    # Можно также использовать dropna() для исключения NaN значений перед заменой, чтобы показать исходное распределение\n    plt.hist(data[col].dropna(), bins=30, alpha=0.5, label='Значения после замены пропусков', color='blue')\n    \n    # Добавляем линии среднего значения до и после\n    plt.axvline(x=mean_before, color='red', linestyle='dashed', linewidth=2, label=f'Среднее до: {mean_before:.2f}')\n    plt.axvline(x=mean_after, color='green', linestyle='dashed', linewidth=2, label=f'Среднее после: {mean_after:.2f}')\n    \n    plt.title(f'Распределение оценок по {col}')\n    plt.xlabel('Оценки')\n    plt.ylabel('Частота')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:29:12.741939Z","iopub.execute_input":"2024-04-08T07:29:12.742955Z","iopub.status.idle":"2024-04-08T07:29:14.127088Z","shell.execute_reply.started":"2024-04-08T07:29:12.742912Z","shell.execute_reply":"2024-04-08T07:29:14.125609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Math Score (Оценки по математике):Если гистограмма показала пик в районе среднего значения, это говорит о том, что значительное количество пропущенных значений было заменено на среднее, что уменьшает разнообразие исходного распределения оценок.\nСреднее значение до и после замены остается неизменным, но стандартное отклонение может уменьшиться, что указывает на снижение изменчивости оценок.\nReading Score (Оценки по чтению):Аналогично, гистограмма могла показать увеличение частоты в районе среднего значения, что также свидетельствует о замене пропущенных данных средними значениями. Распределение оценок после замены может выглядеть менее \"естественно\", особенно если пропущенных значений было много.\nWriting Score (Оценки по письму):Как и в предыдущих случаях, замена пропусков средними значениями создает пик на уровне среднего значения. Это может быть проблематично при анализе распределения, так как искусственно создает более однородный набор данных.\nМеры центральной тенденции, такие как среднее и медиана, не изменяются, но меры разброса, включая дисперсию и стандартное отклонение, могут быть искажены из-за уменьшения разнообразия.\nВо всех трех случаях, важно помнить, что замена пропусков средними значениями может исказить истинное распределение оценок, если пропусков было много. Это также может повлиять на результаты статистического анализа, включая корреляционный и регрессионный анализы, так как данные становятся менее вариативными и менее представительными. В зависимости от доли и распределения пропусков в исходных данных, другие методы импутации, такие как внедрение значений медианы, моды или использование алгоритмов многомерной импутации, могут быть более уместными.","metadata":{}},{"cell_type":"markdown","source":"Для категориальных признаков (например, gender, race_ethnicity, parental_level_of_education, lunch, test_preparation_course), часто используют моду (наиболее часто встречающееся значение):","metadata":{}},{"cell_type":"code","source":"for col in ['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course']:\n    mode_value = data[col].mode()[0]\n    data[col] = data[col].fillna(mode_value)  # Прямое присваивание после замены\n\n    # Визуализация распределения данных\n    plt.figure(figsize=(10, 5))\n    sns.countplot(data=data, x=col, palette='pastel')\n    plt.title(f'Распределение признака {col} после замены пропусков')\n    plt.xticks(rotation=45)  # Поворот меток для лучшей читаемости\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:29:35.658198Z","iopub.execute_input":"2024-04-08T07:29:35.658633Z","iopub.status.idle":"2024-04-08T07:29:37.002977Z","shell.execute_reply.started":"2024-04-08T07:29:35.658594Z","shell.execute_reply":"2024-04-08T07:29:37.001713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В этом коде мы сначала заполняем пропущенные значения в каждом категориальном признаке самым частым значением (модой) для этой колонки. Затем для каждой колонки создается столбчатая диаграмма, показывающая количество наблюдений для каждой категории.","metadata":{}},{"cell_type":"code","source":"print(data.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:39:57.526486Z","iopub.execute_input":"2024-04-08T07:39:57.526906Z","iopub.status.idle":"2024-04-08T07:39:57.537238Z","shell.execute_reply.started":"2024-04-08T07:39:57.526870Z","shell.execute_reply":"2024-04-08T07:39:57.535455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Результат, который получили после использования data.isnull().sum(), показывает, что в каждом столбце датасета теперь 0 пропусков. Это означает, что успешно обработали все пропуски в данных. Теперь датасет полностью заполнен, и можно перейти к следующим шагам обработки данных, таким как кодирование категориальных признаков и нормализация числовых признаков.\n","metadata":{}},{"cell_type":"markdown","source":"**Кодирование категориальных признаков**\nКатегориальные переменные обычно нужно преобразовать в числовые значения, чтобы их можно было использовать в машинном обучении. Вот два распространённых метода:\n1. One-Hot Encoding — создаёт новые столбцы для каждого уникального значения в категориальной переменной, где 1 означает наличие этого значения и 0 его отсутствие.\n2. Label Encoding — присваивает каждому уникальному значению в категориальной переменной целочисленный идентификатор.\nВыбор метода зависит от модели и данных. Например, для линейных моделей предпочтительнее использовать One-Hot Encoding, так как Label Encoding может ввести ложное понятие порядка, которого на самом деле нет.\nДля One-Hot Encoding можно использовать следующий код:","metadata":{}},{"cell_type":"code","source":"# Используем DataFrame только с dummy переменными\n# Преобразуем значения True/False в числа\ndata_dummies_numeric = data_dummies.astype(int)\n\n# Считаем корреляцию между dummy переменными\ncorrelation_matrix = data_dummies_numeric.corr()\n\n# Создаем тепловую карту\nplt.figure(figsize=(15, 15))\nsns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\nplt.title('Тепловая карта корреляции между категориальными переменными')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:12:54.475623Z","iopub.execute_input":"2024-04-08T08:12:54.476030Z","iopub.status.idle":"2024-04-08T08:12:56.363919Z","shell.execute_reply.started":"2024-04-08T08:12:54.475998Z","shell.execute_reply":"2024-04-08T08:12:56.362286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Эта тепловая карта корреляции показывает степень линейной взаимосвязи между различными переменными в вашем наборе данных. Числовые значения на карте представляют коэффициент корреляции Пирсона, который может варьироваться от -1 до +1:\nЗначение +1 указывает на совершенно положительную линейную корреляцию между двумя переменными, т.е. когда одна переменная увеличивается, другая тоже увеличивается.\nЗначение 0 означает отсутствие линейной корреляции.\nЗначение -1 указывает на совершенно отрицательную линейную корреляцию, т.е. когда одна переменная увеличивается, другая уменьшается.\nНа графике видны следующие ключевые моменты:\n-Очень сильная корреляция между оценками по математике (math_score), чтению (reading_score) и письму (writing_score). Это ожидаемо, так как успеваемость учащихся обычно коррелирует между разными предметами.\n-Противоположные значения корреляции между gender_female и gender_male показывают, что это противоположные группы — если учащийся не мужского пола, то он женского (и наоборот), что обусловливает корреляцию -1.\n-Для других переменных значительных корреляций не наблюдается, многие значения близки к нулю, что указывает на отсутствие сильной связи между этими категориями.","metadata":{}},{"cell_type":"markdown","source":"**Нормализация числовых признаков**\nНормализация числовых признаков необходима для того, чтобы все они имели одинаковый масштаб, что особенно важно для моделей, чувствительных к величине данных, например, градиентного спуска.\nMin-Max Scaling — приводит все числа к шкале от 0 до 1.\nСтандартизация (Z-score normalization) — приводит данные к распределению с нулевым средним и единичным стандартным отклонением.\nДля Min-Max Scaling можно использовать следующий код:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Создаём копию исходного DataFrame для масштабированных данных\ndata_scaled = data_encoded.copy()\n\n# Инициализация нормализатора\nscaler = MinMaxScaler()\n\n# Создание фигуры и осей для графиков\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n\n# Список столбцов для нормализации\ncolumn_to_scale = 'math_score'\n\n# График до нормализации\naxes[0].hist(data_encoded[column_to_scale], bins=20, color='blue', alpha=0.7)\naxes[0].set_title(f'Original {column_to_scale}')\n\n# Применение нормализатора\ndata_scaled[column_to_scale] = scaler.fit_transform(data_encoded[[column_to_scale]])\n\n# График после нормализации\naxes[1].hist(data_scaled[column_to_scale], bins=20, color='green', alpha=0.7)\naxes[1].set_title(f'Scaled {column_to_scale}')\n\n# Устанавливаем плотное расположение графиков\nplt.tight_layout()\nplt.show()\n\n# Выведем первые пять строк масштабированных данных для проверки\nprint(data_scaled[[column_to_scale]].head())","metadata":{"execution":{"iopub.status.busy":"2024-04-08T08:24:20.111533Z","iopub.execute_input":"2024-04-08T08:24:20.111970Z","iopub.status.idle":"2024-04-08T08:24:20.749279Z","shell.execute_reply.started":"2024-04-08T08:24:20.111934Z","shell.execute_reply":"2024-04-08T08:24:20.747950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Оригинальная гистограмма (Original math_score): Показывает исходное распределение оценок по математике, где большинство значений сосредоточены в определенном диапазоне. Это может указывать на нормальное распределение оценок или на наличие определенного уровня достижений среди учащихся.\n\nМасштабированная гистограмма (Scaled math_score): Показывает те же данные после применения масштабирования MinMaxScaler, который приводит все значения к диапазону от 0 до 1. Форма распределения остается той же, что указывает на то, что относительные различия между значениями сохраняются, но абсолютный масштаб изменен.\nТакже приведенный фрагмент таблицы показывает первые пять значений масштабированного столбца math_score, где каждое значение теперь находится между 0 и 1. Это свидетельствует о том, что масштабирование было успешно применено.\n\n**Выводы:**\nМасштабирование полезно, когда данные используются в моделях машинного обучения, которые чувствительны к масштабу признаков, например, в алгоритмах на основе расстояний.\nПрименение MinMaxScaler не изменяет форму распределения данных, но переводит все значения в унифицированный масштаб от 0 до 1, что может помочь в стандартизации данных для сравнительного анализа или в улучшении производительности моделей.\nИзменение масштаба не должно влиять на интерпретацию формы распределения данных; распределение оценок по математике сохраняет свои характеристики независимо от масштаба.","metadata":{}}]}